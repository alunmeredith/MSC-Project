---
title: "Fitting degree distribution"
output:
  pdf_document: 
    fig_width: 7
    fig_height: 4
  html_notebook: default
---
```{r load, message=FALSE, include=FALSE}
library(dplyr)
library(poweRlaw)
```
## Fitting degree distribution
The purpose of this section is to use more analytical methods to try and evaluate which distribution best represents the frequency of different orders of patents. 

Because these methods are computationally expensive only a subset of the data will be analysed, choosing the years 1978, 1992, 2002, and 2012. All but the latter are the same years chosen by valverde in his plot and the latter is to represent the new data availible at an appropriate gap (~10 years).

We can use the "poweRlaw" package to fit different models to the in-degree distribution. This package is based on the Newman paper ["Power-law distributions in empirical data" (2009)](http://arxiv.org/pdf/0706.1062.pdf). It includes several methods, 
 * A maximisation of likelihood search to optimise paramters of 4 different discrete models to fit the data:power law, lognormal, exponential and poisson.
    * We have done this for each of the 4 discrete distributions and shown it in a graph. 
 * A likelihood ratio test to compare how two different models fit the data. 
    * We compare log-normal to power law and vice versa. 
 * A bootstrapping method to evaluate a p value for the data being from the distribution. 
    * Currently computationally too expensive
## Methods

Using a bootstrapping method to obtain a p value for distributions

- The paper says that for a given accuracy in the p value the number of simulations required scales $~ \frac{1}{4}\eta^{-1/2}$.
- The paper also approximates a p value cut off of about 0.1 to disregard the hypothesis of the tested distribution. 
- To get an accuracy of 0.01 we need 2500 simulations, this is very computationally expensive so no results yet. 
To find which is a better fit 

Likelihood ratio to compare distributions. 

 * one sided p value is the upper limit on getting that small a log-likelihood ratio if the first distribution (m_pl) is true.
 * two sided p value is the probability of getting a log-likelihood ratio which deviates that much from zero in either direction if the two distributions are equally good. 
 * Test statistic is the sample average of the log-likelihood ratio standardised by an estimated standard deviation. 

## Results

We can see from the graph that exponential and poisson distributions do not fit the data well. Power-law distributions, being perfectly straight on a log-log plot are unable to bend to the dip in the tail and log-normal shows the closest fit while not necessarily describing the tail perfectly in all years. 

For the likelihood ratio test we reafirm what we saw in the graphs where the power-law is optimised for a specific point in the graph where it is straightest but as you move away from that point it performs substantially worse, exempliefied by the behaviour at high orders (in the tail). Furthermore the difference between power law and log-normal increases over time as the network grows larger. 


```{r, include=FALSE}
library(poweRlaw)

load("dat/powerLawFits.rdata")
```

## 1978
```{r 1978, results='hold', echo=FALSE}

pl[[3]]$comparisons$powerlaw[1:3]
pl[[3]]$comparisons$lognormal[1:3]
pl[[3]]$plots$distFit(pl[[3]])
```

### 1992
```{r 1992, results='hold', echo=FALSE}

pl[[1992 - 1975]]$comparisons$powerlaw[1:3]
pl[[1992 - 1975]]$comparisons$lognormal[1:3]
pl[[1992 - 1975]]$plots$distFit(pl[[1992 - 1975]])

```
### 2002
```{r 2002, results='hold', echo=FALSE}

pl[[2002 - 1975]]$comparisons$powerlaw[1:3]
pl[[2002 - 1975]]$comparisons$lognormal[1:3]
pl[[2002 - 1975]]$plots$distFit(pl[[2002 - 1975]])

```
### 2012
```{r 2012, results='hold', echo=FALSE}

pl[[2012 - 1975]]$comparisons$powerlaw[1:3]
pl[[2012 - 1975]]$comparisons$lognormal[1:3]
pl[[2012 - 1975]]$plots$distFit(pl[[2012 - 1975]])

```


```{r}



B <- NULL
for(yr in c(1978, 1992, 2002, 2012)) {
    b <- lapply(pl[[yr - 1975]]$distributions, function(x) {
        ret <- lines(x, draw = FALSE)
        ret$Year <- yr
        return(ret)
        })
    
    b.df <- b[[1]]
    b.df$variable <- names(b)[1]
    for(i in 2:length(b)) {
        b[[i]]$variable <- names(b)[i]
        b.df <- rbind(b.df, b[[i]])
    }
    B <- rbind(B,b.df)
}
B$variable <- as.factor(B$variable)
B$variable <- plyr::revalue(B$variable, c("exp" = "Exponential", "ln" = "Log-Normal", "pois" = "Poisson", "pl" = "Power-Law"))

A <- NULL
for(yr in c(1978, 1992, 2002, 2012)) {
    a <- plot(pl[[yr - 1975]]$distributions$exp, draw = FALSE)
    a$Year <- yr
    a <- as.data.frame(a) 
    names(a) <- c("Order", "Frequency", "Year")
    A <- rbind(A,a)
}

A.df <- NULL
variables <- levels(as.factor(B$variable))
for(var in variables){
    A$variable <- var
    A.df <- rbind(A.df, A)
}
```

```{r}
datA <- dplyr::filter(A.df, !(variable %in% c("ln_equalXmin", "pl_equalXmin")))
datB <- dplyr::filter(B, !(variable %in% c("ln_equalXmin", "pl_equalXmin")))
gg <- ggplot(datA, aes(x = Order, y = Frequency)) + 
    geom_point(colour = "grey")  +
    geom_line(data = datB, aes(x = x, y = y), colour = "black", size = 1.5) +
    facet_grid(Year ~ variable) +
    scale_x_log10() + 
    scale_y_log10(limits = c(1e-5, 1),
                  breaks = 10^(c(-5,-3,-1)), 
                  labels = c(expression(10^-5), expression(10^-3), expression(10^-1))) +
    theme_pub() + 
    theme(legend.position = "none")
gg
```
```{r}
png("Figures/distributionFits.png", width = 1080, height = 820); gg; dev.off()
saveRDS(gg, "Figures/distributionFigs.rds")
```



2 data frames, distribution and fit, "year, xcoord, ycoord"