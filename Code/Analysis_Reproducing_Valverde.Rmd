---
title: "Reproducing Valverde"
output:
  html_notebook: default
  html_document: default
---
```{r setup, include = FALSE}
library(readr)
library(lubridate)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(poweRlaw)
library(gridExtra)
knitr::opts_chunk$set(results = 'hold')
knitr::opts_chunk$set(message = FALSE)
```
The aim of this script is to reproduce two of the plots in the the paper ["Topology and Evolution of Technology Innovation Networks"](http://arxiv.org/pdf/physics/0612030.pdf), which summarises the USPTO patent network. The first figure being reproduced looks at the number of patents over time, and the second is the in-degree distribution and fitting a extended power-law distribution to that. 

<div style="width:900px; height=400px">
![](Figures/ValverdeFigs.png)
</div>

The data being used for these plots in the cleaned concatonated patent data produced by the 'cleaned' script. We have extracted the year into a seperate feature as it is this which the data is summarised over. It contains a list of the patent numbers and date in which those patents were granted. 

```{r read data, echo=TRUE}
# Read data
data <- read_csv("../DataFiles/Cleaned/patent_cat.csv", progress = FALSE)
data$Year <- year(data$Date2)
str(data)
```
## Plot 1: Patents granted by year
The first plot counts the number of patents granted by year, there is an inset which looks at this as a cumulative sum on a log-log scale.



In order to process the data into a tidy format processable by ggplot, we summarise it counting the number of entries (patents) for each year. There are a few outliers (`r nrow(data %>% group_by(Year) %>% summarise(count = n()) %>% filter(!(Year %in% 1976:2015)))`) so this is then filtered to only allow only patents within that range. 

```{r plot1 data summary}
# Summarise results
year_counts <- data %>% group_by(Year) %>% summarise(count = n()) %>% filter(Year %in% 1976:2015)
```

```{r plot1}
(gg1 <- ggplot(data = year_counts, aes(x = Year, y = count)) +
    geom_line() +
    geom_point(shape = 19) +
    scale_x_continuous(limits = c(1970,2020), minor_breaks = seq(1975, 2015, 10) ) +
    scale_y_continuous(limits = c(5e4, 3.5e5), breaks = seq(5e4, 35e4, 5e4)) +
    theme_bw()
 )
```

### Notes on plot1

From our reproduction of the first figure we can make some observations:

 * Although exact numbers aren't given by cross referencing the two graphs certainly __follow the same shape__. 
    * In terms of exact numbers the region leading __up to 1990 seems identical__ but __after this point there may be larger numbers in our data__, e.g. in our data 1997 reaches 1.25e5 but there's is much closer to 1.18 ish. A fairly constant gap of around this ammount seems to persist until the end of the data. 
    * I have parsed foreign patents but on an earlier encarnation when foreign patents were missed there was a large discrepency in number of patents on this graph. So there could be a systematic parsing error or difference in what is being parsed. Either way I believe this my parsing to be more accurate but an analysis into the differences between this graph and other uspto data sources for patent counts has been conducted elsewhere to check for systematic problems.
 * The data has a __jump at the year 1997-1998__. 
 * Valverde's data ends at 2004, __after 2005__ the number of patents becomes much __more erratic__ but also __climbs very steeply__. 
 * Worth noting is that there are 3 different formats in which the data was stored, a propriotary format from 1976:2001, an sgml format from 2001:2004 and an xml format since then (although there have been minor itterations to this format since). 
    * In a previous version of the analysis the method for parsing sgml and propriotary had systematic differences so there was a step at the year 2001. The current parsing method uses the same method for each data type to ensure consistency. Having said this the erratic behaviour starts at the same time xml is begun to be used.  

## Plot1 inset

The inset of plot 1, shows the "Cumulative number of patents on a log-log scale, showing a scaling: $N(t) \sim t^\theta$"
```{r plot1_inset data summary}
year_counts$cum_count <- cumsum(year_counts$count)
year_counts$rel_year <- year_counts$Year - 1975
```

```{r plot1_inset}
gg1b <- ggplot(data = year_counts, aes(x = rel_year, y = cum_count)) + 
    geom_point() +
    scale_x_log10() +
    scale_y_log10() + 
    theme_bw() +
    labs(x = "t", y = "N(t)")
```

```{r plot1_inset linear regression, fig.height=4, fig.width=11}
lm1 <- lm(log10(cum_count) ~ log10(rel_year), data = year_counts)

gg1b.lm1 <- 
    gg1b + 
    geom_abline(intercept = lm1$coefficients[1], slope = lm1$coefficients[2]) + 
    ggtitle("linear fit of all points") +
    annotate(label = round(lm1$coefficients[2],2), x = 10, y = 4e5, geom = "text", size = 5) +
    annotation_logticks(sides = "tblr")

t <- year_counts %>% filter(Year %in% 1985:2004)
lm2 <- lm(log10(cum_count) ~ log10(rel_year), data = t)
gg1b.lm2 <- 
    gg1b + 
    geom_abline(intercept = lm2$coefficients[1], slope = lm2$coefficients[2]) + 
    ggtitle("linear fit over 1985:2014") +
    geom_point(data = t, col = "red") +
    annotate(label = round(lm2$coefficients[2],2), x = 10, y = 4e5, geom = "text", size = 5) +
    annotation_logticks(sides = "tblr")

grid.arrange(gg1b.lm1, gg1b.lm2, ncol=2)
```

### Notes on plot1 inset
 
 * To address the claim that this is an approxmately linear relationship, it does appear to not be linear.
    * Having said that the claim is that it is close to linear which is fairly accurate, the R-squared for the linear fit of all of the data is `r summary(lm1)$r.squared`
 * In fact it also seems like the axes were stretched to make the linear fit look nicer in the plot. Finally to get the fit found in the paper you have to ignore the first set of points (we found 1985:2004 although its conceievable a larger range was used with the differences in patent counts in our analysis) and finally this relationship doesn't hold into the new data since 2004.
 
## Plot2: In degree distribution

```{r plot2 data summary}
degree_distribution <- data %>% group_by(Year, Order) %>% summarise(count = n()) %>% filter(Year %in% c(1984, 1992, 2002, 2012))
degree_distribution <- degree_distribution %>% 
    group_by(Year) %>%
    mutate(group_total = sum(count), freq = count / group_total)
```


```{r lms}
 
lm_func <- function(x, y, year, data = degree_distribution, xmin = 20, xmax = 200) {
    dat <- data %>% filter(Year == year, Order > xmin, Order < xmax)
    dat$Order[dat$Order == 0] <- NA
    
    model <- switch(y, 
           "count" = lm(data = dat, formula = log10(count) ~ log10(Order)),
           "freq" = lm(data = dat, formula = log10(freq) ~ log10(Order)))
    list(func = model$coefficients[2] * log10(x) + model$coefficients[1], coef = model$coefficients)
}
```

```{r raw plot}
gg2a <- ggplot(data = degree_distribution, aes(x = Order, y = count, col = as.factor(Year))) +
    geom_line(size = 0.5) + 
    scale_x_log10(
        breaks = scales::trans_breaks("log10", function(x) 10^x),
        labels = scales::trans_format("log10", scales::math_format(10^.x))
    ) +
    scale_y_log10(
        breaks = scales::trans_breaks("log10", function(x) 10^x),
    labels = scales::trans_format("log10", scales::math_format(10^.x)),
    limits = c(1, 5e4)
    ) +
    annotation_logticks() +
    theme_bw() +
    theme(panel.grid.minor = element_blank()) +
    theme(legend.position = "bottom") +
    stat_function(fun = function(x) lm_func(x, y = "count", year = 1984, xmax = 50)$func, 
                  geom = 'line', colour = 'orange', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "count", year = 1984, xmax = 50)$coef[1],2), 
             x = 10, y = 1e1, geom = "text", size = 3) +
    stat_function(fun = function(x) lm_func(x, y = "count", year = 1992)$func, 
                  geom = 'line', colour = 'green', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "count", year = 1992)$coef[1],2), 
             x = 10, y = 3e1, geom = "text", size = 3) +
    stat_function(fun = function(x) lm_func(x, y = "count", year = 2002)$func, 
                  geom = 'line', colour = 'blue', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "count", year = 2002)$coef[1],2), 
             x = 10, y = 1e2, geom = "text", size = 3) +
    stat_function(fun = function(x) lm_func(x, y = "count", year = 2012)$func, 
                  geom = 'line', colour = 'purple', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "count", year = 2012)$coef[1],2), 
             x = 10, y = 3e2, geom = "text", size = 3)
```


```{r normalised plot, fig.height=5, fig.width=10, message=FALSE, warning=FALSE}
gg2a2 <- ggplot(data = degree_distribution, aes(x = Order, y = freq, colour = as.factor(Year))) + 
    geom_line(size = 0.5) + 
    scale_x_log10(
        breaks = scales::trans_breaks("log10", function(x) 10^x),
        labels = scales::trans_format("log10", scales::math_format(10^.x))
    ) +
    scale_y_log10(
        breaks = scales::trans_breaks("log10", function(x) 10^x),
    labels = scales::trans_format("log10", scales::math_format(10^.x)),
        limits = c(5e-6, 1e0)
    ) +
    annotation_logticks() +
    theme_bw() +
    theme(panel.grid.minor = element_blank()) +
    theme(legend.position = "bottom") +
    stat_function(fun = function(x) lm_func(x, y = "freq", year = 1984, xmax = 50)$func, 
                  geom = 'line', colour = 'orange', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "freq", year = 1984, xmax = 50)$coef[1],2), 
             x = 10, y = 3e-3, geom = "text", size = 3) +
    stat_function(fun = function(x) lm_func(x, y = "freq", year = 1992)$func, 
                  geom = 'line', colour = 'green', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "freq", year = 1992)$coef[1],2), 
             x = 10, y = 1e-3, geom = "text", size = 3) +
    stat_function(fun = function(x) lm_func(x, y = "freq", year = 2002)$func, 
                  geom = 'line', colour = 'blue', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "freq", year = 2002)$coef[1],2), 
             x = 10, y = 3e-4, geom = "text", size = 3) +
    stat_function(fun = function(x) lm_func(x, y = "freq", year = 2012)$func, 
                  geom = 'line', colour = 'purple', linetype = "dashed") +
    annotate(label = round(lm_func(x = NA, y = "freq", year = 2012)$coef[1],2), 
             x = 10, y = 1e-4, geom = "text", size = 3)
grid.arrange(gg2a, gg2a2, ncol = 2)
```
The above shows a raw plot as shown in valverde and a normalised density plot where the count has been divided by the total. We have judged the section of linear power law distribution by eye and fitted a linear model to get the gradient. In this case in the range of 20-200 with the exception of 1984 which uses 50 as its maxmimum order. We can see how a linear model fits well in this region and that values of gradient are higher than that produced by valverde, due to the presumed difference of including foreign patents. 

Typically however heavy tailed plots like above are done using histograms to mitigate the effects of very rare events in the heavy tail. Below we create such a histogram, however there are artefacts due to the fact that order is discrete, as the bins change from containing one order to two etc. 

```{r hist plot}
test <- 1*10^seq(0,log10(4000), length.out = 100)
degree_distribution$bin <- cut(degree_distribution$Order, 
                               breaks = c(0,test),
                               include.lowest = TRUE, 
                               labels = test) %>% as.character() %>% as.numeric()
hist <- degree_distribution %>% group_by(Year, bin) %>% summarise(count = sum(count))
hist <- hist %>% group_by(Year) %>% mutate(group_total = sum(count), freq = count / group_total)

hist2 <-dplyr::filter(hist, Year %in% c(1984,1992,2002,2012))
(gg2a3 <- ggplot(data = hist2, aes(x = bin, y = freq, group = Year, colour = as.factor(Year))) + 
    geom_point() +
    scale_y_log10() + 
    scale_x_log10() +
    theme_few() + 
    annotation_logticks()
)
```
### Notes on plot2

 * In the above histogram plot we can see an apparent "knee" in the linear fit, especially visible in the 2002, and 2012 years. 
 * We see the effect where average number of citations is increasing continue into 2012
 * The big difference between our data and valverde's is that up to a peak of 7-9 the average citations is increasing whereas valerde' only decreases from a peak of 1 citation. 
 * Our data has lower maximum counts and higher maximum order (1e3 rather than 1e2)
    * This could indicate that valverde doesn't include __foreign citations__ whereas we do. 

## Fitting degree distribution

Using only 2002 as an example, we can use the "poweRlaw" package to fit different models to the in-degree distribution. This package is based on the Newman paper ["Power-law distributions in empirical data" (2009)](http://arxiv.org/pdf/0706.1062.pdf). The purpose of that paper and this section is to empirically deduce the underlying models without assuming it is a pwoer law. 

```{r mutate data}
# Filter 2002 and build into a tall format which poweRlaw interacts with. 
t2 <- degree_distribution %>% filter(Year == 2002) %>% group_by() %>% select(Order, count)
vec <- NULL
for(row in seq_len(nrow(t2))) {
    vec <- c(vec, rep(as.numeric(t2[row,"Order"]), t2[row,"count"]))
}
# Remove zeros because log scale can't handle it. 
vec <- vec[vec != 0] 
```

poweRlaw deals with 4 types of discrete model: power law, lognormal, exponential and poisson. We can use poweRlaw to fit these models to the data, estimating their parameters and minimum value of x for which they apply. 
```{r fit models}
m_pl <- displ$new(vec)
est = estimate_pars(m_pl)
est_pl <- estimate_xmin(m_pl)
m_pl$setXmin(est_pl)
print(cat("Power Law \n xmin: " , m_pl$getXmin(), "\n Parameters:", m_pl$getPars(), "\n Goodness of Fit: ", round(est_pl$gof,2)))

m_ln <- dislnorm$new(vec)
est = estimate_pars(m_ln)
est_ln <- estimate_xmin(m_ln)
m_ln$setXmin(est_ln)
print(cat("Log-normal \n xmin: "  , m_ln$getXmin(), "\n Parameters:", m_ln$getPars(), "\n Goodness of Fit: ", round(est_ln$gof, 2)))

m_exp <- disexp$new(vec)
est = estimate_pars(m_exp)
est_exp <- estimate_xmin(m_exp)
m_exp$setXmin(est_exp)
print(cat("Exponential \n xmin: "  , m_exp$getXmin(), "\n Parameters:", m_exp$getPars(), "\n Goodness of Fit: ", round(est_exp$gof, 2)))

m_pois <- dispois$new(vec)
est = estimate_pars(m_pois)
est_pois <- estimate_xmin(m_pois)
m_pois$setXmin(est_pois)
print(cat("Poisson \n xmin: "  , m_pois$getXmin(), "\n Parameters:", m_pois$getPars(), "\n Goodness of Fit: ", round(est_pois$gof, 2)))
```


```{r}
par(mfrow = c(2,2))
par(cex = .5)
par(lwd = 2)
    plot(m_pl, main = "power-law")
    lines(m_pl, col="green") # green
    
    plot(m_ln, main = "log-normal")
    lines(m_ln, col = "red") # red
    
    plot(m_exp, main = "exponential")
    lines(m_exp, col="blue") # blue
    
    plot(m_pois, main = "poisson")
    lines(m_pois, col="orange") # grey
```

The above plot shows the CDF with lines of best fit for each of the distributions, as we can see the Exponential ans poisson distributions only fit to very small low frequency sections of the tail with poor goodness of fit, it is quite easy to discount these as possible underlying mechanisms. The power law and log-normal however have very similar goodness of fits and importantly fit best the centre bulk of the data before extreme effects occur. 

Using a bootstrapping method
```{r, eval=FALSE}
bs_pl = bootstrap_p(m_pl, no_of_sims=2500, threads=8)
bs_ln = bootstrap_p(m_ln, no_of_sims=2500, threads=8)
```

Using a bootstrapping method to obtain a p value for distributions

- The paper says that for a given accuracy in the p value the number of simulations required scales $~ \frac{1}{4}\eta^{-1/2}$.
- The paper also approximates a p value cut off of about 0.1 to disregard the hypothesis of the tested distribution. 
- To get an accuracy of 0.01 we need 2500 simulations, this is would take far too long (~6 hours for power law, and ~ 27hours for lognormal)
- To get around this we will take a sample of the data (currently we have n = `r length(vec)` elements) and the paper shows that n > 1000 seems to accurately differentiate. We will use n = 10,000 to be confident of this. 
```{r, eval=FALSE, warning=FALSE}
set.seed(1)
sample_vec <- sample(vec, 1e5)
m_pl_sample <- displ$new(sample_vec)
est_pl_sample <- estimate_xmin(m_pl_sample)
m_pl_sample$setXmin(est_pl_sample)
bs_pl_sample = bootstrap_p(m_pl_sample, no_of_sims=2500, threads=4)

m_ln_sample <- m_pl <- displ$new(sample_vec)
bs_ln = bootstrap_p(m_ln, no_of_sims=100, threads=4)
```

```{r}
if (!exists(c("bs_pl", "bs_ln"))) load("indegree_bootstrapping.RData")
print(paste("Log-normal p value:", bs_ln$p))
print(paste("Power-law p value:", bs_pl$p))
```

```{r save, echo=FALSE, message=FALSE, warning=FALSE}
png("Figures/gg1.png"); gg1; dev.off()
png("Figures/gg1b.png"); gg1b; dev.off()
png("Figures/gg1blm.png"); grid.arrange(gg1b.lm1, gg1b.lm2, ncol=2); dev.off()
png("Figures/gg2a.png"); gg2a; dev.off()
png("Figures/gg2a2.png"); gg2a2; dev.off()
png("Figures/gg2a3.png"); gg2a3; dev.off()

png("Figures/indegree_models.png")

par(mfrow = c(2,2))
par(cex = .5)
par(lwd = 2)
    plot(m_pl, main = "power-law")
    lines(m_pl, col="green") # green
    
    plot(m_ln, main = "log-normal")
    lines(m_ln, col = "red") # red
    
    plot(m_exp, main = "exponential")
    lines(m_exp, col="blue") # blue
    
    plot(m_pois, main = "poisson")
    lines(m_pois, col="orange") # grey
dev.off()

save(year_counts, file = "year_counts.RData")
save(m_exp, m_ln, m_pois, m_pl, file = "indegree_models.RData")
save(est_exp, est_ln, est_pois, est_pl, file = "indegree_estimates.RData")
save(bs_pl, bs_ln, file = "indegree_bootstrapping.RData")
```