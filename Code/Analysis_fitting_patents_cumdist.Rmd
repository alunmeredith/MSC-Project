---
title: "Curve Fitting Plot1 inset"
output:
  pdf_document: default
  html_notebook: default
---
```{r load data, include=FALSE}
library(ggplot2)
library(gridExtra)
library(scales)
source("plot_theme.R")
load("year_counts.RData")
```

In this notebook we explore the claim that the distribution of patent numbers over time follows a power law distribution. 

As we saw in the reproducing valverde notebook the valverde suggests that the cumluative number of patents is a power law $N(t) \approx t^\theta$. From our fit and including more modern data we can see that this fit doesn't seem appropriate. The two plots below show the cdf of patents each year on a linear and log-log scale respectively. 

```{r plot1_inset, fig.height=4, fig.width=11, echo=F}
gg1b <- ggplot(data = year_counts, aes(x = rel_year, y = cum_count)) + 
    geom_point() +
    theme_bw() +
    labs(x = "t", y = "N(t)")

grid.arrange(gg1b, gg1b + scale_x_log10() + scale_y_log10(), ncol=2)
```

By transforming the data in different ways we can fit standard linear models to predict power law and exponential functions respectively:
The exponential function clearly performs better with low p value and higher R squared. 
```{r, warning=FALSE, echo=F}
attach(year_counts, warn.conflicts = FALSE)
exp.model <- lm(log(count) ~ rel_year)
summary(exp.model)

pl.model <- lm(log(count) ~ log(rel_year))
summary(pl.model)
```

We can visualise these fits onto the data. This clearly shows how the exponential function fits but more importantly when translated to non-cdf how the exponential function still nicely fits the data but the power law looks very odd and is only fitting to one cluster of data, it almost looks like a textbook example of high bias. 
```{r, fig.height=4, fig.width=11, echo=F}
exp.pred <- exp(predict(exp.model, interval = "confidence", level = 0.95))
pl.pred <- exp(predict(pl.model, newdata = data.frame(rel_year = 1:40), interval = "confidence", level = 0.95))

gg1 <- ggplot(data = year_counts, aes(x = rel_year, y = count)) + 
    geom_point() + 
    geom_line(aes(y = exp.pred[,"fit"])) +
    geom_ribbon(aes(ymax = exp.pred[,"upr"], ymin = exp.pred[,"lwr"]), alpha = 0.3) +
    geom_line(aes(y = pl.pred[,"fit"], x = 1:40), linetype = "dashed") +
    theme_pub() +
    theme(panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank()) +
    scale_y_continuous(limits = c(5e4, 3.5e5), 
                   breaks = seq(10, 30, 10)*10^4, 
                   labels = fancy_scientific) +
    labs(x = "Time (years)", y = "Number of Patents")

gg <- ggplot(data = year_counts, aes(x = rel_year, y = cum_count)) +
    geom_point() +
    geom_line(aes(y = cumsum(exp.pred[,"fit"]))) +
    geom_ribbon(aes(ymax = cumsum(exp.pred[,"upr"]), ymin = cumsum(exp.pred[,"lwr"])), alpha = 0.3) +
    theme_pub() +
    geom_line(aes(y = cumsum(pl.pred[,"fit"])), linetype = "dashed") +
    theme(panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank()) +
    scale_y_continuous(limits = c(0, 6e6), 
                   breaks = seq(0, 8e6, length.out = 5), 
                   labels = fancy_scientific) +
    labs(x = "Time (years)", y = "Cumulative number ofPatents")

gg2 <-  gg + scale_x_log10(
    limits = c(1,55),
    breaks  = c(1,5,25)) + 
    scale_y_log10(limits = c(1.5e4, 6e6), 
                  breaks = 10^(1:8), 
                  labels = fancy_scientific)

grid.arrange(gg1, gg, gg2, ncol = 3)
```

# Questions
 - Should I try to fit other distributions
 - Is this enough analysis of this or should I do something more thorough? What would I do?
 - Plots In report should I have plots like this? If so I will make them 
```{r save, include=F}
png("Figures/patentCountFit.png"); gg1; dev.off()
png("Figures/patentCountFit_cum.png"); gg; dev.off()
png("Figures/patentCountFit_cum_loglog.png"); gg2; dev.off()
saveRDS(gg1, "Figures/patentCountFit.rds")
saveRDS(gg, "Figures/patentCountFit.rds")
saveRDS(gg2, "Figures/patentCountFit.rds")
```

